{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망 예측모형 (MLP)\n",
    "딥러닝 라이브러리 Keras 를 사용하여 간단한 모델들을 만드는 방법을 설명합니다.\n",
    "인공신경망의 경우 예전부터 예측 모형에 널리 사용되어 왔습니다.  \n",
    "package 들이 딥러닝 기능을 제공한다고 하는 경우 특별한 설명이 없으면 인공신경망인 경우가 많습니다.  \n",
    "jupyter에서 코드 작성 및 실행이 모두 됩니다.  \n",
    "keras는 별도로 설치해야 하지만 testbed 제공시 이미 깔려 있는 상태로 오픈 예정입니다.\n",
    "\n",
    "#### 준비\n",
    "1. 데이터\n",
    "Keras 에서 기본적으로 몇 가지 데이터를 올려 놓았습니다. (정확히는 첫 사용시 다운받기 때문에 인터넷이 안되는 경우 사용이 안됩니다.)  \n",
    "mnist 데이터를 사용하겠습니다.\n",
    "2. MLP 모델 구성\n",
    "3. MLP 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bwlee/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 준비\n",
    "keras 에서 준비한 기본 데이터를 얻는 방법은 \"data_name\".load_data(argv) 라는 함수를 호출하면 됩니다  \n",
    "데이터 특성에 따라 argv 의 값을 바꾸어 주는데 데이터 타입별로 상세 사항은 keras 홈페이지를 참고하세요  \n",
    "mnist 의 경우 아무것도 입력하지 않아도 됩니다.  \n",
    "이미 train, test, label 이 모두 정해져 있습니다  \n",
    "28\\*28 사이즈의 그림이 60000개, 10000 개 씩 있습니다.  \n",
    "데이터를 살펴보면\n",
    "입력 데이터의 값은 256 색의 값으로 표현되어 있고, 라벨은 해당하는 숫자로 되어 있습니다.\n",
    "이것들을 적용하기 위해 수정이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      " 175  26 166 255 247 127   0   0   0   0]\n",
      "y [5 0 4]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      " 0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      " 0.         0.         0.         0.        ]\n",
      "y [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(x_train[0][5])\n",
    "print('y',y_train[:3])\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0],28*28))/255\n",
    "x_test = x_test.reshape((x_test.shape[0],28*28))/255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(x_train[0][5*28:6*28])\n",
    "print('y',y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 개발\n",
    "대부분의 package 가 제공하는 인공신경망은 MLP 입니다.  \n",
    "Sequential 이라는 클래스는 여러 개의 층으로 구성된 인공신경망을 구성할 수 있습니다.  \n",
    "각 층은 MLP에 해당하는 Dense 클래스로 채워주면 됩니다.  \n",
    "몇 개의 뉴런을 사용할지와 입력의 크기만 알려주면 됩니다.  \n",
    "출력은 10개의 항목에 대한 분류이므로 softmax 함수로 설정해주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "mlp = models.Sequential()\n",
    "mlp.add(layers.Dense(100, activation='relu', input_shape=(28*28,)))\n",
    "mlp.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크를 좀 더 분리해서 표현할 수도 있습니다.  \n",
    "왜 이렇게 같은 걸 어렵게 하냐하면,  \n",
    "네트워크가 복잡해 지면 이런 부분을 위쪽이나 다른 모듈내 별도로 저장해 놓고 호출하는 부분만 중심 코드에 넣으면 코드가 더 깔끔해 집니다.  \n",
    "함수 내에서 패러미터로 넣을 수 있는 부분들은 패러미터로 넣을 수도 있구요,  \n",
    "네트워크 구성 생성하는 부분을 별도로 텍스트 파일로 만든 후 그 부분을 읽어서 작성하는 함수를 만들 수도 있습니다.  \n",
    "(import 만 제외하면 더 짧고 보기가 쉽습니다. 이 부분은 반복적으로 쓰는 만큼 위쪽에 모두 모아놓고 새롭게 만들 때 복사해 붙여 넣으면 됩니다.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def mlp_network():\n",
    "    mlp = models.Sequential()\n",
    "    mlp.add(layers.Dense(100, activation='relu', input_shape=(28*28,)))\n",
    "    mlp.add(layers.Dense(10, activation='softmax'))\n",
    "    return mlp\n",
    "\n",
    "mlp = mlp_network()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습\n",
    "\n",
    "이제 네트워크를 실행하고 학습을 통해 모델을 만들 차례 입니다.  \n",
    "어떤 최적화 방법을 통해 계산을 하고, 어떤 목적 함수(loss)를 사용할 지에 대하여 설정해야 합니다.  \n",
    "최적화 방법으로 가장 간단히, 널리 쓸 수 있는 방법은 'adagrad' 입니다.\n",
    "분류 문제의 경우 'categorical_crossentropy' 가 널리 쓰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2857 - acc: 0.9192\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1841 - acc: 0.9479\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1570 - acc: 0.9563\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1404 - acc: 0.9603\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1285 - acc: 0.9639\n",
      "10000/10000 [==============================] - 0s 21us/step\n",
      "0.13239167961254716 0.9625\n"
     ]
    }
   ],
   "source": [
    "mlp.compile(optimizer='adagrad',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "mlp.fit(x_train, y_train, epochs=5, batch_size = 64)\n",
    "\n",
    "loss, accuracy = mlp.evaluate(x_test, y_test)\n",
    "print(loss, accuracy)\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
