{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Komoran 형태소 분석기 사용 방법",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### 지주 데이터전략부 이병욱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review\n",
    "\n",
    "### 과거 언어처리 방법\n",
    "* 기존 만들어진 word 임베딩을 기반으로 특정 과제에 맞는 복잡한 언어 처리 모델 구성\n",
    "* 많은 경우 사용 과제에 해당하는 데이터만 이용\n",
    "\n",
    "### 최근 트렌드 (Transfer learning)\n",
    "* 많은 데이터를 기반으로 word 레벨 이상의 사전 학습 (sentence, contextualized word)   \n",
    "* 개별 과제에 대하여 튜닝\n",
    "    * 사전 학습으로 일부 구조 처리되어 간단한 모델 추가로 개별 과제 구성\n",
    "\n",
    "<img src=\"transfer_learning.PNG\" width=\"600\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review : KB에서의 NLP 적용을 위한 고려사항\n",
    "#### 효율적 진행 방안\n",
    "* pre-training을 통해 sentence embedding 생성\n",
    "* API로 공유 \n",
    "    > sent1 = \"나는 문장입니다.\"  \n",
    "    > embed1 = get_embed(sent1)  \n",
    "* 현업 직원은 pretrained model을 가지고 현업 데이터로 finetune\n",
    "    * 내부 과제 진행 시 파일 복사 등을 통해 쉽게 내부 구축 \n",
    "    > model1 = load_model(pretrained_model)  \n",
    "    model1.train(new_data)  \n",
    "    model1.evaluate(new_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review : KB에서의 NLP 적용을 위한 고려사항 (계속)\n",
    "#### 진행 계획(안)\n",
    "한글 전처리(형태소 분석) --> word 레벨 임베딩 --> sentence 레벨 임베딩 --> API 개발 --> 현업 적용\n",
    "1. 한글 전처리\n",
    "    * 형태소 분석(Sejong corpus) \n",
    "    * 활용 : 개별 모델 구성 시 기반 작업\n",
    "2. word 레벨 embedding 적용 \n",
    "    * Word2vec, Glove, ... (news, wikipeaid, book, ...) \n",
    "    * 활용 : 텍스트 모델 구성을 위한 word 임베딩, 단어 기반 의미 검색\n",
    "3. sentence 레벨 embedding\n",
    "    * baseline : power mean (Glove, word2vec, fasttext?, postprocessing)\n",
    "    * advanced models : ELMO, universal sentence encoder, quick-thought, ...\n",
    "    * 활용 : 문장 단위 의미 검색, 각종 텍스트 처리 간단화\n",
    "4.  API in DoKB\n",
    "5. 현업 튜닝을 통한 과제 적용\n",
    "    * 뉴스 분석\n",
    "    * 텍스트 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 배경\n",
    "* 한글 전처리 과정에 형태소 분석 적용하는 것이 일반적\n",
    "* 형태소 분석기는 general한 말 사용으로 구성\n",
    "* 비즈니스 과제에서는 내부적 용어 다수 포함  \n",
    "  --> 형태소 분석기에서 인식 못하는 경우 다수\n",
    "* 사용자 사전 작성 등을 통한 보완 필요\n",
    "* 무료 형태소 분석기 중 komoran, kkoma 비교적 높은 평가\n",
    "* kkoma 에 비해 komoran이 더 빠르고, 품사 태그가 (널리 쓰이는) 세종 말뭉치와 동일\n",
    "\n",
    "## 목표\n",
    "* 내부 자료에 맞도록 komoran 형태소분석기 구성 변경 및 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Komoran 소개\n",
    "\n",
    "* Original Komoran in Java\n",
    "    * [komoran v3](https://github.com/shin285/KOMORAN), 비교적 최근 업데이트\n",
    "    * [komoran v2](https://github.com/shineware/komoran-2.0)\n",
    "* Komoran in Python  \n",
    "    * 자바 버전 내부적으로 호출\n",
    "    * [PyKomoran](https://github.com/shineware/PyKOMORAN)\n",
    "    * [komoran3py](https://github.com/lovit/komoran3py)\n",
    "    * [Konlpy](https://konlpy-ko.readthedocs.io/ko/v0.5.1/api/konlpy.tag/#module-konlpy.tag._komoran)\n",
    "        * 최신 버전은 0.5.1\n",
    "        * version 0.5 이후 Komoran v3 적용  \n",
    "        * Komoran API 는 Komoran class 내 세 개의 method 로 구성\n",
    "        \n",
    "```java\n",
    "# Komoran class in Konlpy\n",
    "class konlpy.tag._komoran.Komoran(jvmpath=None, userdic=None, \n",
    "                                  modelpath=None, max_heap_size=1024){\n",
    "    morphs(phrase) : Parse phrase to morphemes.\n",
    "    nouns(phrase) : Noun extractor.\n",
    "    pos(phrase, flatten=True, join=False) : POS tagger.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Komoran 사용법\n",
    "* 기본 모델 사용하기\n",
    "    * 예) Konlpy 사용\n",
    "    * 단점 :\n",
    "        * 사용자 단어 사용시 속도 저하\n",
    "        * 많은 단어 추가 시 작동 원활하지 않음\n",
    "            * ~ 15만 개 추가시 작동 오류 및 메모리 부족 발생\n",
    "        * 자체 사전 크기 적음\n",
    "            * default ~3만 형태소 사용  \n",
    "            * kkoma(~30만), 세종 코퍼스(~20만)\n",
    "* 별도 모델 개발 후 사용하기\n",
    "    * 다수의 사용자 단어 추가 가능\n",
    "    * Komoran 모델 재구성 --> Komoran instance 구성에서 신규 모델 로드  \n",
    "    \n",
    "```java\n",
    "class konlpy.tag._komoran.Komoran(jvmpath=None, userdic=None, \n",
    "                                  <span style=\"color:red\">modelpath=None</span>, \n",
    "                                  max_heap_size=1024)\n",
    "```\n",
    "\n",
    "> 단어 숫자는 얼마나 필요한가?  \n",
    "* 최근 딥러닝 모델들은 수만 개 정도의 단어 사용  \n",
    "* 위에서 언급한 단어 수는 형태소 분석에 사용  \n",
    "* 실제 딥러닝에서 사용되는 단어 수와는 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Komoran custom 구성 방법\n",
    "* [참조] [komoran 공식 문서](https://docs.komoran.kr/?utm_source=komoran-repo&utm_medium=Referral&utm_campaign=github-demo) : 설명 자세하지 않아 API 부분 확인 필요  \n",
    "* konlpy 내 다른 형태소 분석기와는 다르게 komoran 사전은 모델 내 간접적으로 포함\n",
    "* default : stable 모델, github 내 full 모델 제공 --> 사용자 모델 필요\n",
    "\n",
    "### komoran 수정 방법\n",
    " \n",
    "1. corpus build \n",
    "    * 관심 텍스트 문서를 기반으로 사전 파일 생성  \n",
    "      예) github 내 corpus_build 디렉토리  \n",
    "2. model build\n",
    "    * 사전 파일을 기반으로 모델 파일 생성  \n",
    "      예) github 내 models_full, models_light 디렉토리  \n",
    "3. model load\n",
    "    * 모델 파일 위치 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Komoran 모델 build 예시\n",
    "아래 방식을 참고하여 사용하고자 하는 데이터 별로 적용 가능  \n",
    "\n",
    "### 1. corpus_build 내 기본 사전(dic.word) 이용\n",
    "* 텍스트 파일로 구성\n",
    "* 각 형태소와 형태소의 빈도 기록\n",
    "* 한 개 형태소는 여러 품사 가질 수 있음\n",
    ">```꼬지\tNNG:5  \n",
    "탄로\tNNG:10```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Komoran 모델 생성 예시 (계속)\n",
    "### 2. 세종말뭉치 파일 전처리\n",
    "#### [세종 말뭉치](https://ithub.korean.go.kr/user/main.do)\n",
    "* 국립국어원에서 배포한 자료로 한글 분석에서 널리 사용되는 기본 자료  \n",
    "* 국립국어원 언어정보나눔터 --> 말뭉치 --> 기타 참고자료 --> 본인 필요자료 이용\n",
    "* 현대구어 형태분석 말뭉치, 현대문어 형태분석 말뭉치 자료 사용  \n",
    "  예시) [현대구어 형태 분석](5CT_0013.txt), [현대구어 형태 분석](BTAA0001.txt)\n",
    "* 원본 파일에 대한 전처리 필요 --> 아래 공개 소스 활용  \n",
    "\n",
    "#### [sejong_corpus_cleaner](https://github.com/lovit/sejong_corpus_cleaner)\n",
    "* 세종말뭉치는 2차 배포가 자유롭지 않아 직접 파일을 받아 전처리 스크립트 실행 필요\n",
    "* 설명을 따라 디렉토리, 파일 구축 후 script 실행\n",
    "    * scripts/build_eojeol_morphtag.py, scripts/build_eojeol_morphtag_table.py\n",
    "\n",
    "> sejong_corpus_cleaner/scripts/build_eojeol_morphtag_table.py\n",
    "    * inputs : 세종말뭉치 원본 파일\n",
    "    * outputs : eojeol_morphtag_table_written.txt,  \n",
    "                eojeol_morphtag_table_colloquial.txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Komoran 모델 생성 예시 (계속)\n",
    "### 3. 세종말뭉치 단어 기본 사전에 추가\n",
    "* 세종 말뭉치의 경우 사람이 작업한 라벨이므로 추가\n",
    "\n",
    "#### [get_sejong_corpus.ipynb](get_sejong_corpus.ipynb)\n",
    "\n",
    "* 전처리 파일로부터 세종 말뭉치 내 형태소 추출 후 sejong.dic 으로 저장\n",
    "* inputs : eojeol_morphtag_table_written.txt, eojeol_morphtag_table_colloquial.txt\n",
    "* outputs : sejong.dic\n",
    "\n",
    "#### [build_word_dic_v2.ipynb](build_word_dic_v2.ipynb)\n",
    "\n",
    "* 기존 사전과 세종 말뭉치 합하여 dic2.word 로 저장\n",
    "* inputs : sejong.dic, dic.word\n",
    "* outputs : dic2.word          \n",
    "* sejong_corpus_cleaner 에서 계산된 발생 빈도 합산해 업데이트\n",
    "\n",
    "> 전처리 유의 사항 (예외 case)  \n",
    "* 기호 등이 있는 경우 \"\" 로 형태소 묶어 기록  \n",
    "  일반 case) 달려가 --> 달려가, 예외 case) , 달려가 --> \", 달려가 \"  \n",
    "* 세종 말뭉치 내 일부 tag 은 komoran tag 에 없음  \n",
    "  (구어에서만 발생, komoran 이 Konlpy 와 동일한 tag 을 쓴다고 알려져 있으나  \n",
    "   세종말뭉치에 예외적인 tag들 있음)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Komoran 모델 생성 예시 (계속)\n",
    "\n",
    "### 4. 신규 단어 추출\n",
    "\n",
    "#### [noun_extractor_v2.ipynb](noun_extractor_v2.ipynb) : \n",
    "* 신규 단어도 기본 단어장에 포함시키는 것이 유리\n",
    "* soynlp 명사 추출기 이용하여 신규 단어 추출 후 기존 사전에 추가\n",
    "* inputs : dic2.word\n",
    "* outputs : dic2.word (rename later with dic.word)  \n",
    "\n",
    "> 적용 구성 \n",
    "* noun_extractor v1, v2 중 v1 사용  \n",
    "* 2018년 1월부터 10월 까지 뉴스 ~40만건 사용\n",
    "* ~40000 형태소 신규 추출 후 기존 사전에 없는 ~15000 개 선택  \n",
    "* 명사추출기(통계적 추출)는 사용 문서 양이 많을수록 정확도 향상   \n",
    "   --> 50000만 뉴스씩 뭉치 구성    \n",
    "* 명사 확률값이 나오므로 확률 값, 빈도 등에 대한 필터링 가능  \n",
    "(빈도\\*확률 값을 신규 빈도로 적용)\n",
    "* 추출 명사에 대해 한글만 추가  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Komoran 모델 생성 예시 (계속)\n",
    "### 5. 신규 모델 생성\n",
    "#### [ModelBuildTest.java](ModelBuildTest.java)\n",
    "* inputs : dic.word (in corpus_build)\n",
    "* outputs : observation.model (in models)\n",
    "```java\n",
    "ModelBuilder builder = new ModelBuilder();\n",
    "builder.setExternalDic(\"../corpus_build/user.dic\");\n",
    "builder.buildPath(\"../corpus_build\");\n",
    "builder.save(\"models\");\n",
    "```\n",
    "* 실행 \n",
    "    1. 신규 dic.word 를 사전 폴더 (default : corpus_build) 에 넣기   \n",
    "    2. Komoran.jar 생성 :  \n",
    "        * docs.komoran.kr 참조  \n",
    "          ( --> 설치하기 --> Gradle 이용하기, Jar 파일 만들기)\n",
    "    3. 컴파일\n",
    "        * javac -cp \".:./libs/KOMORAN.jar:\" ModelBuildTest.java \n",
    "    4. 모델 생성\n",
    "        * java -cp \".:./libs/KOMORAN.jar:\" ModelBuildTest\n",
    "    5. 모델 로드\n",
    "        * komoran instance 호출시 모델 경로 설정\n",
    "\n",
    "            ```python\n",
    "            # PyKomoran 이용할 경우,\n",
    "            import PyKomoran as komo\n",
    "            komoran = komo.Komoran(\".../build/models\")\n",
    "            anal4 = komoran4.get_plain_text(content1)            \n",
    "            ```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Komoran 모델 생성 예시 (계속)\n",
    "\n",
    "### 6. 복합 형태소 축약(optional)\n",
    "* 적용 전후 결과 비교 등을 통해 적용 여부 판단 필요\n",
    "\n",
    "#### [morpheme_analyzer_v2.ipynb](morpheme_analyzer_v2.ipynb)\n",
    "* 새롭게 만든 모델로 형태소분석기 호출\n",
    "* 분석할 문장에 형태소 분석기 적용\n",
    "* L-R corpus 로 변환 (https://github.com/lovit/sejong_corpus_cleaner)\n",
    "* 형태소 분석 결과 비교(위 파일 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 기타 필요 추가 작업\n",
    "\n",
    "* 형태소 sequence --> 단어 기반 sequence\n",
    "* kkoma 사전 단어들 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
